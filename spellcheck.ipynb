{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Ass4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhGKKtgz0S84"
      },
      "source": [
        "Name:    Aleezeh Usman\n",
        "\n",
        "Roll #:  18I-0529\n",
        "\n",
        "Email:   i180529@nu.edu.pk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZevqnt0ReV9"
      },
      "source": [
        "# **Getting the Data and formatting it into Unigram and Error Model Tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB_gwl7eRQ9T",
        "outputId": "be56409e-1b81-46e1-dc68-eab6cab79182"
      },
      "source": [
        "#libraries needed to read the text - we have used google drive for file reading\n",
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "training_set = list()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spAePoHbXP9G"
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "#read file and convert it into usable list which will be used to make the training set\n",
        "#basic data set that will be used for unigram model\n",
        "with open('/content/drive/My Drive/Classroom/Natural Language Processing (Spring 2021)/Notebooks/data.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "    data_set = Counter(re.findall(r'\\w+', text.lower()))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA00lEAq0SXW",
        "outputId": "8626b4d7-8276-43c2-8b10-187743c83694"
      },
      "source": [
        "#misspellings data set that will be used for error matrices\n",
        "with open('/content/drive/My Drive/Classroom/Natural Language Processing (Spring 2021)/Notebooks/misspellings.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    errors = list(reader)\n",
        "f.close()\n",
        "\n",
        "print(len(data_set))\n",
        "print(len(errors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35834\n",
            "36101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfDAGGtjc4Jt"
      },
      "source": [
        "#convert the raw data from misspellings file to usable formatted dictionary\n",
        "misspellings = dict()\n",
        "\n",
        "for each in errors:\n",
        "  tempstore = \"\"\n",
        "  templist =  list()\n",
        "  for letter in each[1]:\n",
        "    if letter != \" \" and letter != \"\\t\":\n",
        "      tempstore += letter \n",
        "    else:\n",
        "      if tempstore != \"\":\n",
        "        templist.append(tempstore)\n",
        "      tempstore = \"\"\n",
        "  if tempstore != \"\":\n",
        "    templist.append(tempstore)\n",
        "  misspellings[each[0]] = templist.copy()\n",
        "\n",
        "values = data_set.values()\n",
        "totalwords = sum(values)\n",
        "#convert count in data set into a probability of occurence of the word in the data set \n",
        "for key in data_set:\n",
        "  data_set[key] = data_set[key]/totalwords\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szr9ityicvKy"
      },
      "source": [
        "\"\"\"checkcount = 0\n",
        "for key in data_set:\n",
        "  print(key, end = \" -> \")\n",
        "  print(data_set[key])\n",
        "  checkcount += data_set[key]\n",
        "\n",
        "print(\"TOTAL: \")\n",
        "print(checkcount)\n",
        "\n",
        "values = data_set.values()\n",
        "totalwords = sum(values)\n",
        "print(totalwords)\n",
        "\n",
        "print(max(values))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LySfVyM6YgEO"
      },
      "source": [
        "#list that is only to help us properly format error model tables\n",
        "alphabets = ['#','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','$']\n",
        "#error model tables\n",
        "#each error model table will be a 2D dictionary so each alphabet has a list of all alphabets count so error probabilities can be calculated\n",
        "insert_table = dict()                                                          \n",
        "delete_table = dict()\n",
        "transpose_table = dict()\n",
        "substitute_table = dict()\n",
        "#Bigram model matrix - 2D dict\n",
        "#row depicts prev word, column depicts next word\n",
        "bigram_matrix = dict()\n",
        "#Unigram Model - simple dictionary storing count of each character\n",
        "unigram = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRLy9Uvd3dXE"
      },
      "source": [
        "# **FUNCTIONS USED FOR IMPLEMENTATION**\n",
        "- insert , delete, substitute, transpose most important functions used to build error tables and find candidates from data set given a misspelled word\n",
        "- Build Tables Function that will populate and store count for each operation in each table\n",
        "- Build character level Bigram and Unigram used to get probabilities later\n",
        "- Get Best Options function which will be used in case no candidates one edit distance away available so will give naive best option found\n",
        "- Generate Candidates function to get the best candidates given a misspelled word and their probabilities too\n",
        "- get P(x|w) function which will calculate the probability of the misspelled word x occuring when w was intended"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkuUmnBURbU4"
      },
      "source": [
        "def printErrorTable(table, alphabets):\n",
        "  print(\"   \", end = \"\")\n",
        "  for alph in alphabets:\n",
        "    print (alph, end = \" \")\n",
        "  print()\n",
        "  for key in table:\n",
        "    print(key, end = \": \")\n",
        "    for key2 in table[key]:\n",
        "      print(table[key][key2], end = \" \")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3Cjn-q8wNRc"
      },
      "source": [
        "def BuildBigram(bigram, alphabets, data_set):\n",
        "  #initialize Bigram Matrix with zeroes at first\n",
        "  for letter in alphabets:\n",
        "    tempdict = dict()                                                            #each dictionary key will be storing another dictionary to make 2D dict so we can access each alphabet through each alphabet\n",
        "  \n",
        "    for letter2 in alphabets:\n",
        "      tempdict[letter2] = 0                                                      #set all counts to zero in the table at first\n",
        "    bigram[letter] = tempdict\n",
        "\n",
        "  #count consecutive letter occurences in each word of the data set\n",
        "  for key in data_set:\n",
        "    i = 0\n",
        "    while i < len(key):\n",
        "      if i == 0:\n",
        "        bigram['#'][key[i]] += 1\n",
        "      else:\n",
        "        bigram[key[i-1]][key[i]] += 1\n",
        "      i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKxcF5xIxR7E"
      },
      "source": [
        "def BuildUnigram(unigram, alphabets, data_set):\n",
        "  for letter in alphabets:\n",
        "    unigram[letter] = 0\n",
        "\n",
        "  for key in data_set:\n",
        "    for letter in key:\n",
        "      unigram[letter] += 1\n",
        "      \n",
        "  unigram['#'] = len(data_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5lSfkp758mU"
      },
      "source": [
        "#function to build all the error tables using misspellings dict and alphabets list\n",
        "def BuildTables(ins_tab, del_tab, sub_tab, tran_tab, misspellings, alphabets):\n",
        "  #initialize the table at first\n",
        "  for letter in alphabets:\n",
        "    tempdict1 = dict()                                                          #since everything in python is by reference to make sure that we are not accessing the same memory\n",
        "    tempdict2 = dict()\n",
        "    tempdict3 = dict()\n",
        "    tempdict4 = dict()\n",
        "  \n",
        "    for letter2 in alphabets:\n",
        "      tempdict1[letter2] = 0                                                    #set all counts to zero in the table at first\n",
        "      tempdict2[letter2] = 0\n",
        "      tempdict3[letter2] = 0\n",
        "      tempdict4[letter2] = 0\n",
        "    insert_table[letter] = tempdict1\n",
        "    delete_table[letter] = tempdict2\n",
        "    transpose_table[letter] = tempdict3\n",
        "    substitute_table[letter] = tempdict4\n",
        "\n",
        "  #set values in the table using information about the misspellings\n",
        "  for key in misspellings:\n",
        "    for each in misspellings[key]:                                              #for each misspelling corresponsing to an actual word test it for all operations (insert, delete, substitute, transpose)\n",
        "      letters = insert_check(key, each)                                         #then increment count in the correct table\n",
        "      if letters[0] != False:\n",
        "        #print('INSERT TABLE ENTRY: ', end = \"\")\n",
        "        #print(letters)\n",
        "        ins_tab[letters[0]][letters[1]] += 1\n",
        "      letters = delete_check(key, each)\n",
        "      if letters[0] != False:\n",
        "        #print('DELETE TABLE ENTRY: ', end = \"\")\n",
        "        #print(letters)\n",
        "        del_tab[letters[0]][letters[1]] += 1\n",
        "      letters = substitute_check(key, each)\n",
        "      if letters[0] != False:\n",
        "        #print('SUBSTITUTE TABLE ENTRY: ', end = \"\")\n",
        "        #print(letters)\n",
        "        sub_tab[letters[0]][letters[1]] += 1\n",
        "      letters = transpose_check(key, each)\n",
        "      if letters[0] != False:\n",
        "        #print('TRANSPOSE TABLE ENTRY: ', end = \"\")\n",
        "        #print(letters)\n",
        "        tran_tab[letters[0]][letters[1]] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef5BfF26SZqk"
      },
      "source": [
        "def insert_check(actual,misspell):\n",
        "  storebefore = list()                                                          # to store the word before the inserted word\n",
        "\n",
        "  if (len(misspell) != len(actual)+1):                                          #if length of misspelling is less than or equal to actual then it is not insertion so no point running loop\n",
        "    storebefore.append(False)\n",
        "    return storebefore\n",
        "  \n",
        "  i = 0\n",
        "  j = 0\n",
        "  count = 0                                                                     #keep count of similar words, for insertion should be equal to length of actual word\n",
        "  incorrectcount = 0\n",
        "  while i < len(actual) and incorrectcount <= 1:                                #stop loop if more than 1 edit distance at the moment\n",
        "    if actual[i] == misspell[j]:                                                #if similarity found keep count\n",
        "      count += 1\n",
        "      if ( i == len(actual)-1) and (storebefore == []) and (len(misspell) > len(actual)) and ( count == len(actual)):   \n",
        "        j += 1                                                                  #if entire word was same and end has come but actual word has not ended that means insertion is at end\n",
        "        storebefore.append(misspell[j-1])\n",
        "        storebefore.append(misspell[j])\n",
        "    elif (incorrectcount < 1 and actual[i] == misspell[j+1]):                   #if current word does not match but next does then that means this is where insertion has occured but if already an incorrect word has occurred and according to assignment document only 1 edit distance must exist so keep check\n",
        "      incorrectcount += 1\n",
        "      if i == 0:\n",
        "        storebefore.append('#')                                                 #insertion is at the start of the word\n",
        "        storebefore.append(misspell[j])\n",
        "      else:\n",
        "        storebefore.append(misspell[j-1])                                       #insertion occured somewhere in the middle of the word\n",
        "        storebefore.append(misspell[j])\n",
        "      i -= 1\n",
        "    else:\n",
        "      incorrectcount += 1\n",
        "    i += 1\n",
        "    j += 1\n",
        "\n",
        "  if count != len(actual) or storebefore == [] or incorrectcount > 1:           #if nothing was found in loop or more incorrect words than 1 than not insertion\n",
        "    storebefore = list()                                                        #just in case something was inserted in storebefore\n",
        "    storebefore.append(False)\n",
        "\n",
        "  return storebefore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxecVCY9lC9-"
      },
      "source": [
        "def delete_check(actual,misspell):\n",
        "  storebefore = list()                                                          # to store the word before the inserted word\n",
        "\n",
        "  if (len(misspell) != len(actual)-1):                                          #if length of misspelling is longer than or equal to actual then it is not deletion so no point running loop\n",
        "    storebefore.append(False)\n",
        "    return storebefore\n",
        "  \n",
        "  i = 0\n",
        "  j = 0\n",
        "  count = 0                                                                     #keep count of similar words, for deletion should be equal to 1 less than length of actual word\n",
        "  incorrectcount = 0\n",
        "  while j < len(misspell) and incorrectcount <= 1:                              #stop loop if more than 1 edit distance\n",
        "    if actual[i] == misspell[j]:                                                #if similarity found keep count\n",
        "      count += 1\n",
        "      if ( j == len(actual)-2) and (storebefore == []) and (len(misspell) < len(actual)) and ( count == len(actual)-1):\n",
        "        i += 1                                                                  #if entire word was same and end has come but actual word has not ended that means deletion is at end\n",
        "        storebefore.append(actual[i-1])\n",
        "        storebefore.append(actual[i])\n",
        "    elif incorrectcount < 1 and (actual[i+1] == misspell[j]):                   #if current word does not match but next does then that means this is where deletion has occuredd\n",
        "      incorrectcount += 1\n",
        "      if i == 0:\n",
        "        storebefore.append('#')                                                 #deletion is at the start of the word\n",
        "        storebefore.append(actual[i])\n",
        "      else:\n",
        "        storebefore.append(actual[i-1])                                         #deletion occured somewhere in the middle of the word\n",
        "        storebefore.append(actual[i])\n",
        "      j -= 1\n",
        "    else:\n",
        "      incorrectcount += 1\n",
        "    i += 1\n",
        "    j += 1\n",
        "\n",
        "  if (count != len(actual)-1) or storebefore == [] or incorrectcount > 1:       #if one word less than actual word did not exist in the misspelling than not a case of deletion\n",
        "    storebefore = list()                                                        #just in case something was inserted in storebefore\n",
        "    storebefore.append(False)\n",
        "\n",
        "  return storebefore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqofUSoUpfhF"
      },
      "source": [
        "def substitute_check(actual,misspell):\n",
        "  storeletters = list()\n",
        "\n",
        "  if(len(actual) != len(misspell)):                                             #length must be same, if not no need to check\n",
        "    storeletters.append(False)\n",
        "    return storeletters\n",
        "\n",
        "  i = 0\n",
        "  count = 0\n",
        "  while i < len(actual):\n",
        "    if actual[i] == misspell[i]:                                                #if similarity found keep count\n",
        "      count += 1\n",
        "    else:\n",
        "      storeletters.append(actual[i])                                            #if no similarity then consider than the position for subsitution\n",
        "      storeletters.append(misspell[i])\n",
        "    i += 1\n",
        "\n",
        "  if (count != len(actual)-1) or storeletters == []:                            #substitution only valid IF all letter other than 1 match in misspell and actual word\n",
        "    storeletters = list()\n",
        "    storeletters.append(False)\n",
        "\n",
        "  return storeletters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwanyNfV4A1S"
      },
      "source": [
        "def transpose_check(actual, misspell):\n",
        "  storeletters = list()\n",
        "\n",
        "  if(len(actual) != len(misspell)):                                             #if length not same no need to check\n",
        "    storeletters.append(False)\n",
        "    return storeletters\n",
        "\n",
        "  i = 0\n",
        "  count = 0\n",
        "  while i < len(actual):\n",
        "    if actual[i] == misspell[i]:                                                #count similarities\n",
        "      count += 1\n",
        "    else:\n",
        "      if ( i != len(actual)-1):                                                 #if not similar compare the current pair of letters with the pair of letters from misspelling, if they are simply interchanged it is a transpose\n",
        "        if actual[i] == misspell[i+1] and misspell[i] == actual[i+1]:\n",
        "          storeletters.append(actual[i])\n",
        "          storeletters.append(misspell[i])\n",
        "          i+=1                                                                  #move on to the next unchecked letter\n",
        "    i+=1\n",
        "  \n",
        "  if (count != len(actual)-2) or storeletters == []:                            #all letters save for 2 MUST be same for transpose to be valid\n",
        "    storeletters = list()\n",
        "    storeletters.append(False)\n",
        "\n",
        "  return storeletters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBCXsLs72YVG"
      },
      "source": [
        "#The probability of getting x after w using the error models/tables\n",
        "def get_Pxw(operation, ins_tab, del_tab, sub_tab, tran_tab, prev,curr, bigram, unigram):\n",
        "  if operation == \"insert\":\n",
        "    count = ins_tab[prev][curr]     #number of times current letter has been inserted after given prev letter\n",
        "    total = unigram[prev]           #total number of the prev letter occured in the corpus/training set\n",
        "\n",
        "  elif operation == \"delete\":       \n",
        "    count = del_tab[prev][curr]     #number of times curr letter has been deleted after the prev letter\n",
        "    total = bigram[prev][curr]      #number of times prev curr have occured together in same seq in the corpus\n",
        "\n",
        "  elif operation == \"substitute\":\n",
        "    count = sub_tab[prev][curr]     #number of times current letter has replaced the given prev letter\n",
        "    total = unigram[prev]           #total number of the prev letter occured in the corpus/training set\n",
        "\n",
        "  elif operation == \"transpose\":\n",
        "    count = tran_tab[prev][curr]    #number of times current letter and prev letter have interchanged their positions     \n",
        "    total = bigram[prev][curr]      #number of times prev curr have occured together in same seq in the corpus\n",
        "\n",
        "  probability = count/total*100\n",
        "  return probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB0B5A9G4fZh"
      },
      "source": [
        "#this will only be used in case no candidates are possible with the given data set thus we will simply look for words most similar to the current word\n",
        "def get_best_options(misspell, data_set):\n",
        "  toReturn = list()\n",
        "\n",
        "  for each in data_set:\n",
        "    templist = list()\n",
        "    i = 0\n",
        "    if len(each) < len(misspell): \n",
        "      i = len(each)\n",
        "    elif len(misspell) < len(each):\n",
        "      i = len(misspell)\n",
        "    j = 0\n",
        "    count = 0\n",
        "    while j < i:\n",
        "      if (each[j] == misspell[j]):\n",
        "        count += 1\n",
        "      j += 1 \n",
        "    if count > 0 :\n",
        "      templist.append(each)\n",
        "      templist.append(count)\n",
        "      toReturn.append(templist)\n",
        "  \n",
        "  toReturn.sort(key = lambda x: x[1])                                           #sort so all closest to word are at end and we can easily get the best options\n",
        "\n",
        "  finalReturn = list()\n",
        "  if len(toReturn) > 4:                                                         #only return the best 4 options\n",
        "    i = len(toReturn) - 1\n",
        "    while i > len(toReturn) - 6:                                        \n",
        "      finalReturn.append(toReturn[i][0])\n",
        "      i -= 1\n",
        "  else:                                                                         #if less than 4 than return all found options\n",
        "    for each in toReturn:\n",
        "      finalReturn.append(each[0])\n",
        "\n",
        "  return finalReturn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FANT8oztLEBs"
      },
      "source": [
        "#function to generate a list of candidate words that are only one edit distance away or provide options in case no candidate words available\n",
        "def Generate_Candidate_Words(misspell, data_set, insert_table, delete_table, substitute_table, transpose_table, bigram, unigram):\n",
        "  toReturn = list()\n",
        "  finalReturn = list()\n",
        "\n",
        "  for each in data_set:\n",
        "    yesorno = insert_check(each, misspell)                                      #check if word is one edit away\n",
        "    if (yesorno[0] != False):\n",
        "      templist = list()\n",
        "      ProbXW = get_Pxw(\"insert\",insert_table,delete_table,substitute_table, transpose_table, yesorno[0], yesorno[1], bigram, unigram)\n",
        "      ProbW = data_set[each]\n",
        "      Prob = ProbXW * ProbW                                                     #calculate probability and store\n",
        "      templist.append(each)\n",
        "      templist.append(Prob)\n",
        "      toReturn.append(templist)\n",
        "\n",
        "    yesorno = delete_check(each, misspell)                                      #check if word one delete away\n",
        "    if (yesorno[0] != False):\n",
        "      templist = list()\n",
        "      ProbXW = get_Pxw(\"delete\",insert_table,delete_table,substitute_table, transpose_table, yesorno[0], yesorno[1], bigram, unigram)\n",
        "      ProbW = data_set[each]\n",
        "      Prob = ProbXW * ProbW                                                     #calculate probability and store\n",
        "      templist.append(each)\n",
        "      templist.append(Prob)\n",
        "      toReturn.append(templist)\n",
        "\n",
        "    yesorno = substitute_check(each, misspell)                                  #check if word one substitute away\n",
        "    if (yesorno[0] != False):\n",
        "      templist = list()\n",
        "      ProbXW = get_Pxw(\"substitute\",insert_table,delete_table,substitute_table, transpose_table, yesorno[0], yesorno[1], bigram, unigram)\n",
        "      ProbW = data_set[each]\n",
        "      Prob = ProbXW * ProbW                                                     #calculate probability and store\n",
        "      templist.append(each)\n",
        "      templist.append(Prob)\n",
        "      toReturn.append(templist)\n",
        "\n",
        "    yesorno = transpose_check(each, misspell)                                   #check if word one transposition away\n",
        "    if (yesorno[0] != False):\n",
        "      templist = list()\n",
        "      ProbXW = get_Pxw(\"transpose\",insert_table,delete_table,substitute_table, transpose_table, yesorno[0], yesorno[1], bigram, unigram)\n",
        "      ProbW = data_set[each]\n",
        "      Prob = ProbXW * ProbW                                                     #calculate probability and store\n",
        "      templist.append(each)\n",
        "      templist.append(Prob)\n",
        "      toReturn.append(templist)\n",
        "\n",
        "  if toReturn == []:                                                            #in case there are no candidate words\n",
        "    finalReturn.append(\"do not process\")                                        #in case there were no candidate words let program know bayes theorem and calculation can not be applied simply chose best\n",
        "  else:\n",
        "    finalReturn.append(\"process\")                                               #in case candidate words where generated process further for best candidate based on error probabilities!\n",
        "  \n",
        "  finalReturn.append(toReturn)\n",
        "  return finalReturn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "715WXS3_AUQ6"
      },
      "source": [
        "# **Selection Model Function which is basically combining all the functions and finding the final most optimal/probable answer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX9hmn1j-JaV"
      },
      "source": [
        "def Selection_Model(misspell, data_set, insert_table, delete_table, substitute_table, transpose_table, bigram, unigram):\n",
        "  if misspell not in data_set:\n",
        "    cand = Generate_Candidate_Words(misspell, data_set, insert_table, delete_table, substitute_table, transpose_table, bigram, unigram)\n",
        "    if cand[0] == 'do not process':                   #in case no candidate words found that are one edit distance away\n",
        "      print(\"NO CANDIDATE WORDS COULD BE GENERATED FOR THE GIVEN MISSPELLED WORD\\n<<<< CLOSEST NAIVE OPTION BEING DISPLAYED>>>>\")\n",
        "      options = get_best_options(misspell, data_set)  #find best possible options from the data set\n",
        "      print(options)\n",
        "      print(\"BEST OPTION: \", end = \"\" )               #choose closest option\n",
        "      print(options[0])\n",
        "    if cand[0] == 'process':\n",
        "      cand[1].sort(key = lambda x: x[1])              #sort list of candidates from lowest to highest probability\n",
        "      print(\"CANDIDATE WORDS GENERATED: \", end = \"\")\n",
        "      print(cand[1])\n",
        "      print(\"BEST CANDIDATE: \", end = \"\")\n",
        "      finalcandidate = cand[1][len(cand[1])-1][0]     #choose candidate with highest probability\n",
        "      print(finalcandidate)\n",
        "  else:\n",
        "    print(\"<<<< WORD IS CORRECTLY SPELLED >>>>\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxJM3m4sjGgI"
      },
      "source": [
        "## **MAIN IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIouFdXAs_R"
      },
      "source": [
        "#Build and print tables\n",
        "BuildTables(insert_table,delete_table, substitute_table, transpose_table, misspellings, alphabets)\n",
        "BuildBigram(bigram_matrix, alphabets, data_set)\n",
        "BuildUnigram(unigram, alphabets, data_set)\n",
        "\n",
        "#print(\"<<<<<INSERT TABLE>>>>>\")\n",
        "#printErrorTable(insert_table, alphabets)\n",
        "#print()\n",
        "#print(\"<<<<<DELETE TABLE>>>>>\")\n",
        "#printErrorTable(delete_table, alphabets)\n",
        "#print()\n",
        "#print(\"<<<<<SUBSTITUTE TABLE>>>>>\")\n",
        "#printErrorTable(substitute_table, alphabets)\n",
        "#print()\n",
        "#print(\"<<<<<TRANSPOSE TABLE>>>>>\")\n",
        "#printErrorTable(transpose_table, alphabets)\n",
        "#print()\n",
        "\n",
        "#printErrorTable(bigram_matrix, alphabets)\n",
        "#print(unigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pFVD_xSBDI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2dcec84-e069-44db-96c9-6347832dd1a1"
      },
      "source": [
        "#run main selection function on different words for testing (this will do all the work for us)\n",
        "Selection_Model('kaa', data_set, insert_table, delete_table, substitute_table, transpose_table, bigram_matrix, unigram)\n",
        "print()\n",
        "Selection_Model('zzx', data_set, insert_table, delete_table, substitute_table, transpose_table, bigram_matrix, unigram)\n",
        "print()\n",
        "Selection_Model('ksd', data_set, insert_table, delete_table, substitute_table, transpose_table, bigram_matrix, unigram)\n",
        "print()\n",
        "Selection_Model('nf', data_set, insert_table, delete_table, substitute_table, transpose_table, bigram_matrix, unigram)\n",
        "print()\n",
        "Selection_Model('xxxxxxxxxxxxxxx', data_set, insert_table, delete_table, substitute_table, transpose_table, bigram_matrix, unigram)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<<<< WORD IS CORRECTLY SPELLED >>>>\n",
            "\n",
            "CANDIDATE WORDS GENERATED: [['zz', 2.4683817134132404e-07], ['zzz', 2.8201718183470976e-05]]\n",
            "BEST CANDIDATE: zzz\n",
            "\n",
            "CANDIDATE WORDS GENERATED: [['ksa', 3.0552189908465237e-07], ['kd', 3.1349597265038964e-07], ['kad', 4.332682159732273e-07], ['ksy', 6.000011428120248e-07], ['ksm', 9.987738217512806e-07], ['kse', 1.1065861881710007e-06], ['kud', 1.1371770601814005e-06], ['ks', 1.214324306560603e-06], ['khd', 1.456115551858701e-06], ['sd', 1.6216346192021304e-06], ['fsd', 1.743040099162904e-06], ['ksb', 1.891807679452134e-06], ['kid', 4.860102583375424e-06], ['ksi', 8.533675429572745e-06], ['asd', 1.6082735358730125e-05]]\n",
            "BEST CANDIDATE: asd\n",
            "\n",
            "CANDIDATE WORDS GENERATED: [['fn', 0.0], ['nfo', 6.009520036453333e-08], ['nv', 6.615397876194119e-08], ['yf', 7.260359559433092e-08], ['cf', 1.164615499127969e-07], ['nl', 2.5086819643108476e-07], ['jf', 2.8331326344063876e-07], ['nr', 2.992034909132975e-07], ['nk', 3.5365454765932385e-07], ['hf', 3.749653781610388e-07], ['nj', 4.1552611971293685e-07], ['ef', 4.452431178619199e-07], ['nm', 4.817052690551631e-07], ['nb', 5.429946263340986e-07], ['pf', 5.620523425707845e-07], ['mf', 5.920960598803045e-07], ['np', 6.071553083326377e-07], ['nz', 6.628062008239256e-07], ['nw', 7.588444881195816e-07], ['rf', 9.169139237665568e-07], ['df', 9.283855886558083e-07], ['nx', 1.085347682099868e-06], ['nc', 1.1029593844682528e-06], ['ns', 1.1619029931742897e-06], ['lf', 1.201610724306852e-06], ['nt', 1.7867721373591174e-06], ['ng', 2.174692416292309e-06], ['tf', 2.5617224096998142e-06], ['sf', 2.7718540354680703e-06], ['nn', 3.7302118004381366e-06], ['kf', 4.151360305600987e-06], ['ff', 4.213424735558343e-06], ['bf', 4.809380976102017e-06], ['gf', 4.866478362680789e-06], ['nu', 5.437562963275554e-06], ['af', 1.0942021885299789e-05], ['if', 1.5778699549568264e-05], ['uf', 1.6033165095441936e-05], ['nh', 3.827376197070027e-05], ['nd', 5.491107314963419e-05], ['ny', 0.00011038889543134592], ['ni', 0.00017911120915361985], ['of', 0.00026151319923046985], ['no', 0.0002895708628019827], ['na', 0.001554737440743608], ['ne', 0.011643196225937383]]\n",
            "BEST CANDIDATE: ne\n",
            "\n",
            "NO CANDIDATE WORDS COULD BE GENERATED FOR THE GIVEN MISSPELLED WORD\n",
            "<<<< CLOSEST NAIVE OPTION BEING DISPLAYED>>>>\n",
            "['xx', 'xironi', 'urganox', 'anyx', 'excalier']\n",
            "BEST OPTION: xx\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}